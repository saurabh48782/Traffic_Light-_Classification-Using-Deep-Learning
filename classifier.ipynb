{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRISHTI GUPTA\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9259, 32, 32, 3) (9259,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 28804     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 29,700\n",
      "Trainable params: 29,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRISHTI GUPTA\\anaconda3\\envs\\Keras_env\\lib\\site-packages\\ipykernel_launcher.py:64: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5925 samples, validate on 1482 samples\n",
      "Epoch 1/20\n",
      "5925/5925 [==============================] - 6s 1ms/step - loss: 0.3622 - accuracy: 0.8839 - val_loss: 0.2104 - val_accuracy: 0.9298\n",
      "Epoch 2/20\n",
      "5925/5925 [==============================] - 4s 697us/step - loss: 0.2061 - accuracy: 0.9286 - val_loss: 0.1842 - val_accuracy: 0.9312\n",
      "Epoch 3/20\n",
      "5925/5925 [==============================] - 4s 684us/step - loss: 0.1829 - accuracy: 0.9381 - val_loss: 0.1821 - val_accuracy: 0.9271\n",
      "Epoch 4/20\n",
      "  32/5925 [..............................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9688"
     ]
    }
   ],
   "source": [
    "# Importing important libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Making a Convolutional Neural Network\n",
    "def CNNetwork():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Setting activation function as relu\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4))\n",
    "    # Applying softmax activation function\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(Training_data, model):\n",
    "    # Reading my Training dataset\n",
    "    x_,y_ = pickle.load( open(Training_data, \"rb\" ) )\n",
    "    # Training dataset has 9259 samples\n",
    "    print(x_.shape,y_.shape)\n",
    "    \n",
    "    random_state = 130\n",
    "    # Dividing my dataset for training and validation using train_test_split method from sklearn library\n",
    "    # 80% dataset is used for training and remaining 20% for validation purpose\n",
    "    X_train, x_validation, Y_train, y_validation = train_test_split(x_, y_, train_size = 0.80,\n",
    "                                                                    test_size = 0.2,\n",
    "                                                                    random_state = random_state)\n",
    "    # Preprocessing of data\n",
    "    X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "    \n",
    "    # LabelBinarizer() method from sklearn.preprocessing module binarizes our labels using One-vs-All approach\n",
    "    binarizered_label = LabelBinarizer()\n",
    "    \n",
    "    # fit_transfrom() method transforms multi-class labels into binary labels\n",
    "    # Y_labels is a one-hot-encoded training labels\n",
    "    Y_train_labels = binarizered_label.fit_transform(Y_train)\n",
    "    \n",
    "    # model.summary() prints a string summary of the network.\n",
    "    model.summary()\n",
    "\n",
    "    ''' model.compile() method configures the  model for training purpose\n",
    "    It takes in three parameters:\n",
    "    - adam is a  type of optimizer which is a stochastic gradient descent method\n",
    "    - categorical_crossentropy is a loss function which computes the loss between labels and predictions.\n",
    "    - third parameter is a list of metrics to be evaluated by the model\n",
    "    '''\n",
    "    model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "    \n",
    "    # model.fit() trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "    history = model.fit(X_normalized, Y_train_labels, nb_epoch=20, validation_split=0.2)\n",
    "    \n",
    "    # summarizing history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarizing history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # Saving my model in 'model.h5' file\n",
    "    model.save('model.h5')\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def test_model(file_path, model):\n",
    "    \n",
    "    # Reading my testing dataset\n",
    "    X_test,Y_test = pickle.load( open(file_path, \"rb\" ) )\n",
    "    \n",
    "    # There are 1030 samples in test dataset\n",
    "    print(X_test.shape,Y_test.shape)\n",
    "    \n",
    "    ## Preprocessing of testing data\n",
    "    \n",
    "    X_test_standard = np.array(X_test / 255.0 - 0.5 )\n",
    "    \n",
    "    # LabelBinarizer() method from sklearn.preprocessing module binarizes our labels using One-vs-All approach\n",
    "    binarizered_label = LabelBinarizer()\n",
    "    # binarizered_label.fit_transform() method fits label binarizer and transforms multi-class labels to binary labels.\n",
    "    Y_test_labels = binarizered_label.fit_transform(Y_test)\n",
    "\n",
    "    print(\"\\n\\n----------Testing my Model----------------\")\n",
    "    \n",
    "    # model.evaluate() method returns the loss value & metrics values for the model in testing phase.\n",
    "    metrics = model.evaluate(X_test_standard, Y_test_labels)\n",
    "    for i in range(len(model.metrics_names)):\n",
    "        metric_name = model.metrics_names[i]\n",
    "        metric_value = metrics[i]\n",
    "        # Prints metrics like loss and accuraxy\n",
    "        print('{}: {}'.format(metric_name, metric_value))\n",
    "\n",
    "\n",
    "def test_sample_img(file_path, model):\n",
    "    \n",
    "    # Firstly, resizing the input image to [32,32,3] shape and then feeding it into neural network\n",
    "\n",
    "    desired_dim=(32,32)\n",
    "    img = cv2.imread(file_path)\n",
    "    resized_img = cv2.resize(img, desired_dim, interpolation=cv2.INTER_LINEAR)\n",
    "    img_ = np.expand_dims(np.array(resized_img), axis=0)\n",
    "    \n",
    "    # Predicting the class of the input sample image\n",
    "    predicted_state = model.predict_classes(img_)\n",
    "\n",
    "    return predicted_state\n",
    "\n",
    "# Driver Function\n",
    "if __name__ == \"__main__\":\n",
    "    model = CNNetwork()\n",
    "    Training_set = \"./datasets/Train_Dataset.p\"\n",
    "    Testing_set = \"./datasets/Test_Dataset.p\"\n",
    "\n",
    "    # Training my CNN Model\n",
    "    train_model(Training_set, model)\n",
    "\n",
    "    # Testing my CNN Model\n",
    "    test_model(Testing_set, model=load_model('model.h5'))\n",
    "\n",
    "    # Testing a single image (any random traffic light image) after training our dataset\n",
    "    flag = True\n",
    "    file_path = './datasets/yellow.jpg'\n",
    "    states = ['red', 'yellow', 'green', 'off']\n",
    "    if flag:\n",
    "        predicted_state = test_sample_img(file_path, model=load_model('model.h5'))\n",
    "        for idx in predicted_state:\n",
    "            print(\"Colour inferred from the sample image is: \", states[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
